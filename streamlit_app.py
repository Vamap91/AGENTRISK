import streamlit as st
import json
import datetime
import base64
import io
import os
import re
from typing import Dict, List, Tuple, Any

# ImportaÃ§Ãµes condicionais
try:
    from reportlab.pdfgen import canvas
    from reportlab.lib.pagesizes import letter, A4
    from reportlab.lib.colors import HexColor
    from reportlab.lib.styles import getSampleStyleSheet
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
    PDF_AVAILABLE = True
except ImportError:
    st.error("âŒ ReportLab Ã© obrigatÃ³rio para gerar PDFs!")
    st.stop()

try:
    import openai
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="AgentRisk - AnÃ¡lise de CÃ³digo",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ConfiguraÃ§Ã£o OpenAI
@st.cache_resource
def get_openai_client():
    """Inicializa cliente OpenAI"""
    if not OPENAI_AVAILABLE:
        return None
    try:
        if "OPENAI_API_KEY" in st.secrets:
            return OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
        return None
    except Exception:
        return None

# CSS
st.markdown("""
<style>
.main-header {
    background: linear-gradient(90deg, #1e3a8a 0%, #3b82f6 100%);
    padding: 2rem;
    border-radius: 10px;
    color: white;
    text-align: center;
    margin-bottom: 2rem;
}
.risk-card {
    border: 1px solid #e5e7eb;
    border-radius: 8px;
    padding: 1rem;
    margin: 0.5rem 0;
    background: white;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}
.risk-high { border-left: 5px solid #dc2626; background: #fef2f2; }
.risk-medium { border-left: 5px solid #f59e0b; background: #fffbeb; }
.risk-low { border-left: 5px solid #10b981; background: #f0fdf4; }
.score-container {
    text-align: center;
    padding: 2rem;
    border-radius: 10px;
    margin: 1rem 0;
    box-shadow: 0 4px 6px rgba(0,0,0,0.1);
}
.score-high { background: #fef2f2; border: 2px solid #dc2626; }
.score-medium { background: #fffbeb; border: 2px solid #f59e0b; }
.score-low { background: #f0fdf4; border: 2px solid #10b981; }
</style>
""", unsafe_allow_html=True)

# DefiniÃ§Ã£o dos 15 riscos
AGENTIC_AI_RISKS = {
    "1": {
        "nome": "Desalinhamento de Objetivos",
        "descricao": "Sistema pode buscar objetivos diferentes dos pretendidos",
        "categoria": "GovernanÃ§a",
        "patterns": ["todo", "fixme", "hack", "workaround", "temporary"]
    },
    "2": {
        "nome": "AÃ§Ãµes AutÃ´nomas Indesejadas", 
        "descricao": "ExecuÃ§Ã£o de aÃ§Ãµes sem aprovaÃ§Ã£o humana adequada",
        "categoria": "Autonomia",
        "patterns": ["auto", "automatic", "without_approval", "direct_action"]
    },
    "3": {
        "nome": "Uso Indevido de APIs",
        "descricao": "UtilizaÃ§Ã£o inadequada de APIs e serviÃ§os externos",
        "categoria": "IntegraÃ§Ã£o", 
        "patterns": ["requests.", "fetch(", "axios", "api_key", "http"]
    },
    "4": {
        "nome": "DecepÃ§Ã£o e ViÃ©s de Persona",
        "descricao": "Comportamentos enviesados baseados na persona do agente",
        "categoria": "Comportamento",
        "patterns": ["bias", "fake", "deceive", "manipulate", "persona"]
    },
    "5": {
        "nome": "PersistÃªncia de MemÃ³ria Inadequada",
        "descricao": "RetenÃ§Ã£o inapropriada de informaÃ§Ãµes sensÃ­veis",
        "categoria": "MemÃ³ria",
        "patterns": ["cache", "session", "memory", "persist", "store"]
    },
    "6": {
        "nome": "TransparÃªncia Limitada",
        "descricao": "Dificuldade em explicar decisÃµes do sistema",
        "categoria": "TransparÃªncia",
        "patterns": ["black_box", "unexplained", "no_log", "silent"]
    },
    "7": {
        "nome": "Vulnerabilidades de SeguranÃ§a",
        "descricao": "ExposiÃ§Ã£o a ataques e falhas de seguranÃ§a",
        "categoria": "SeguranÃ§a",
        "patterns": ["eval", "exec", "unsafe", "hardcoded", "password"]
    },
    "8": {
        "nome": "Conformidade RegulatÃ³ria",
        "descricao": "NÃ£o atendimento a regulamentaÃ§Ãµes (LGPD, AI Act)",
        "categoria": "Compliance",
        "patterns": ["gdpr", "lgpd", "compliance", "regulation", "audit"]
    },
    "9": {
        "nome": "Escalabilidade e Performance",
        "descricao": "LimitaÃ§Ãµes na capacidade de escalar adequadamente",
        "categoria": "Performance", 
        "patterns": ["bottleneck", "slow", "timeout", "performance"]
    },
    "10": {
        "nome": "Qualidade dos Dados",
        "descricao": "Problemas na qualidade e integridade dos dados",
        "categoria": "Dados",
        "patterns": ["validate", "sanitize", "clean", "quality"]
    },
    "11": {
        "nome": "Monitoramento e Auditoria",
        "descricao": "AusÃªncia de monitoramento e trilhas de auditoria",
        "categoria": "Observabilidade",
        "patterns": ["log", "monitor", "audit", "track", "observe"]
    },
    "12": {
        "nome": "GestÃ£o de ExceÃ§Ãµes",
        "descricao": "Tratamento inadequado de situaÃ§Ãµes excepcionais",
        "categoria": "Robustez",
        "patterns": ["try", "except", "catch", "error", "fallback"]
    },
    "13": {
        "nome": "DependÃªncias Externas",
        "descricao": "Riscos de dependÃªncia de serviÃ§os externos",
        "categoria": "DependÃªncia",
        "patterns": ["import", "require", "dependency", "external"]
    },
    "14": {
        "nome": "Impacto nos Stakeholders",
        "descricao": "Efeitos nÃ£o intencionais em usuÃ¡rios e funcionÃ¡rios",
        "categoria": "Social",
        "patterns": ["user", "customer", "employee", "stakeholder"]
    },
    "15": {
        "nome": "EvoluÃ§Ã£o Descontrolada",
        "descricao": "MudanÃ§as nÃ£o supervisionadas via aprendizado contÃ­nuo",
        "categoria": "EvoluÃ§Ã£o",
        "patterns": ["learning", "adapt", "evolve", "self_modify"]
    }
}

# Tipos de arquivo suportados
SUPPORTED_EXTENSIONS = [
    'py', 'js', 'ts', 'java', 'cs', 'php', 'rb', 'go', 'cpp', 'c',
    'json', 'yaml', 'yml', 'xml', 'sql', 'md', 'txt'
]

class CodeAnalyzer:
    """Analisador de cÃ³digo para detecÃ§Ã£o de riscos"""
    
    def __init__(self, openai_client=None):
        self.client = openai_client
        
    def analyze_files(self, uploaded_files) -> Dict:
        """Analisa mÃºltiplos arquivos"""
        if not uploaded_files:
            return {"error": "Nenhum arquivo fornecido"}
            
        files_data = []
        total_lines = 0
        
        for uploaded_file in uploaded_files:
            try:
                content = self._read_file_content(uploaded_file)
                if content:
                    analysis = self._analyze_single_file(uploaded_file.name, content)
                    files_data.append(analysis)
                    total_lines += analysis.get('lines_count', 0)
            except Exception as e:
                st.warning(f"âš ï¸ Erro ao processar {uploaded_file.name}: {str(e)}")
                continue
                
        if not files_data:
            return {"error": "Nenhum arquivo vÃ¡lido"}
            
        cross_analysis = self._cross_file_analysis(files_data)
        global_score = self._calculate_global_score(files_data, cross_analysis)
        
        return {
            "files_analyzed": len(files_data),
            "total_lines": total_lines,
            "global_score": global_score,
            "global_level": self._get_risk_level(global_score),
            "files_data": files_data,
            "cross_analysis": cross_analysis,
            "risks_summary": self._generate_risks_summary(files_data),
            "analysis_date": datetime.datetime.now().isoformat(),
            "analysis_method": "AnÃ¡lise Multi-Arquivo"
        }
    
    def _read_file_content(self, uploaded_file) -> str:
        """LÃª conteÃºdo do arquivo"""
        try:
            uploaded_file.seek(0)
            content = uploaded_file.read()
            
            # Tentar decodificar
            for encoding in ['utf-8', 'latin-1', 'cp1252']:
                try:
                    return content.decode(encoding)
                except UnicodeDecodeError:
                    continue
                    
            return str(content)
        except Exception as e:
            st.error(f"Erro ao ler {uploaded_file.name}: {str(e)}")
            return ""
    
    def _analyze_single_file(self, filename: str, content: str) -> Dict:
        """Analisa um arquivo"""
        file_ext = os.path.splitext(filename.lower())[1][1:]  # Remove o ponto
        
        lines = content.split('\n')
        lines_count = len(lines)
        char_count = len(content)
        
        classification = self._classify_file(filename, content)
        risk_patterns = self._detect_risk_patterns(content)
        security_issues = self._detect_security_issues(content)
        file_score = self._calculate_file_score(risk_patterns, security_issues, content)
        
        return {
            "filename": filename,
            "file_type": self._get_file_type(file_ext),
            "classification": classification,
            "lines_count": lines_count,
            "char_count": char_count,
            "file_score": file_score,
            "risk_level": self._get_risk_level(file_score),
            "risk_patterns": risk_patterns,
            "security_issues": security_issues,
            "content_preview": content[:500] + "..." if len(content) > 500 else content,
            "critical_lines": self._find_critical_lines(lines)
        }
    
    def _get_file_type(self, extension: str) -> str:
        """Retorna tipo do arquivo baseado na extensÃ£o"""
        type_map = {
            'py': 'Python', 'js': 'JavaScript', 'ts': 'TypeScript',
            'java': 'Java', 'cs': 'C#', 'php': 'PHP', 'rb': 'Ruby',
            'go': 'Go', 'cpp': 'C++', 'c': 'C', 'json': 'JSON',
            'yaml': 'YAML', 'yml': 'YAML', 'xml': 'XML',
            'sql': 'SQL', 'md': 'Markdown', 'txt': 'Text'
        }
        return type_map.get(extension, 'Unknown')
    
    def _classify_file(self, filename: str, content: str) -> str:
        """Classifica propÃ³sito do arquivo"""
        filename_lower = filename.lower()
        content_lower = content.lower()
        
        if any(term in filename_lower for term in ['main', 'app', 'index']):
            return "entry_point"
        elif any(term in filename_lower for term in ['auth', 'login', 'security']):
            return "security"
        elif any(term in filename_lower for term in ['config', 'setting']):
            return "configuration"
        elif any(term in filename_lower for term in ['api', 'route']):
            return "api_layer"
        elif any(term in filename_lower for term in ['model', 'schema']):
            return "data_model"
        elif any(term in filename_lower for term in ['test', 'spec']):
            return "testing"
        else:
            return "business_logic"
    
    def _detect_risk_patterns(self, content: str) -> Dict:
        """Detecta padrÃµes de risco"""
        content_lower = content.lower()
        detected_risks = {}
        
        for risk_id, risk_info in AGENTIC_AI_RISKS.items():
            risk_score = 0
            found_patterns = []
            
            for pattern in risk_info.get('patterns', []):
                if pattern in content_lower:
                    risk_score += 20
                    found_patterns.append(pattern)
            
            # PadrÃµes crÃ­ticos
            critical_patterns = {
                'eval(': 50, 'exec(': 50, 'password': 30, 
                'secret': 30, 'admin': 20, 'root': 25
            }
            
            for pattern, score_add in critical_patterns.items():
                if pattern in content_lower:
                    risk_score += score_add
                    found_patterns.append(pattern)
            
            detected_risks[risk_id] = {
                "score": min(100, max(0, risk_score)),
                "level": self._get_risk_level(risk_score),
                "patterns_found": found_patterns,
                "risk_name": risk_info["nome"]
            }
        
        return detected_risks
    
    def _detect_security_issues(self, content: str) -> List[Dict]:
        """Detecta problemas de seguranÃ§a"""
        issues = []
        lines = content.split('\n')
        
        security_patterns = {
            'hardcoded_secrets': [
                r'password\s*=\s*["\'][^"\']+["\']',
                r'api_key\s*=\s*["\'][^"\']+["\']',
                r'secret\s*=\s*["\'][^"\']+["\']'
            ],
            'dangerous_functions': [
                r'eval\s*\(',
                r'exec\s*\(',
                r'system\s*\('
            ]
        }
        
        for line_num, line in enumerate(lines, 1):
            for issue_type, patterns in security_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, line, re.IGNORECASE):
                        issues.append({
                            "type": issue_type,
                            "line": line_num,
                            "content": line.strip(),
                            "severity": "HIGH" if issue_type == 'dangerous_functions' else "MEDIUM",
                            "description": self._get_security_description(issue_type)
                        })
        
        return issues
    
    def _get_security_description(self, issue_type: str) -> str:
        """DescriÃ§Ã£o do problema de seguranÃ§a"""
        descriptions = {
            'hardcoded_secrets': 'Credenciais hardcoded no cÃ³digo',
            'dangerous_functions': 'Uso de funÃ§Ãµes perigosas (eval, exec)'
        }
        return descriptions.get(issue_type, 'Problema de seguranÃ§a')
    
    def _calculate_file_score(self, risk_patterns: Dict, security_issues: List, content: str) -> float:
        """Calcula score de risco do arquivo"""
        base_score = 20
        patterns_score = sum(r['score'] for r in risk_patterns.values()) / len(risk_patterns)
        
        security_score = 0
        for issue in security_issues:
            security_score += 30 if issue['severity'] == 'HIGH' else 15
        
        # Fatores que reduzem risco
        good_practices = ['try:', 'except:', 'logging', 'validate', 'sanitize']
        reduction = sum(5 for practice in good_practices if practice in content.lower())
        
        final_score = base_score + (patterns_score * 0.6) + security_score - reduction
        return max(0, min(100, final_score))
    
    def _get_risk_level(self, score: float) -> str:
        """Converte score em nÃ­vel"""
        if score >= 70:
            return "Alto"
        elif score >= 40:
            return "Moderado"
        else:
            return "Baixo"
    
    def _find_critical_lines(self, lines: List[str]) -> List[Dict]:
        """Encontra linhas crÃ­ticas"""
        critical_lines = []
        keywords = ['password', 'secret', 'token', 'eval', 'exec', 'admin']
        
        for line_num, line in enumerate(lines, 1):
            if any(keyword in line.lower() for keyword in keywords):
                critical_lines.append({
                    "line_number": line_num,
                    "content": line.strip(),
                    "reason": "ContÃ©m palavras-chave crÃ­ticas"
                })
        
        return critical_lines[:5]
    
    def _cross_file_analysis(self, files_data: List[Dict]) -> Dict:
        """AnÃ¡lise cruzada entre arquivos"""
        cross_risks = []
        
        config_files = [f for f in files_data if f['classification'] == 'configuration']
        api_files = [f for f in files_data if f['classification'] == 'api_layer']
        auth_files = [f for f in files_data if f['classification'] == 'security']
        
        # Verificar credenciais em configs
        for config_file in config_files:
            if any(issue['type'] == 'hardcoded_secrets' for issue in config_file['security_issues']):
                cross_risks.append({
                    "type": "credentials_exposure",
                    "description": f"Credenciais em {config_file['filename']} afetam sistema",
                    "severity": "HIGH",
                    "affected_files": [f['filename'] for f in files_data if f != config_file]
                })
        
        # APIs sem autenticaÃ§Ã£o
        if api_files and not auth_files:
            cross_risks.append({
                "type": "api_without_auth",
                "description": "APIs sem sistema de autenticaÃ§Ã£o",
                "severity": "HIGH",
                "affected_files": [f['filename'] for f in api_files]
            })
        
        return {
            "risks_found": len(cross_risks),
            "cross_risks": cross_risks,
            "system_architecture": self._analyze_architecture(files_data)
        }
    
    def _analyze_architecture(self, files_data: List[Dict]) -> Dict:
        """Analisa arquitetura do sistema"""
        arch = {
            "entry_points": len([f for f in files_data if f['classification'] == 'entry_point']),
            "api_layers": len([f for f in files_data if f['classification'] == 'api_layer']),
            "data_models": len([f for f in files_data if f['classification'] == 'data_model']),
            "security_files": len([f for f in files_data if f['classification'] == 'security']),
            "config_files": len([f for f in files_data if f['classification'] == 'configuration']),
            "test_files": len([f for f in files_data if f['classification'] == 'testing'])
        }
        
        completeness = 0
        if arch["entry_points"] > 0: completeness += 20
        if arch["api_layers"] > 0: completeness += 15
        if arch["security_files"] > 0: completeness += 25
        if arch["test_files"] > 0: completeness += 20
        if arch["config_files"] > 0: completeness += 10
        if arch["data_models"] > 0: completeness += 10
        
        arch["completeness_score"] = completeness
        return arch
    
    def _calculate_global_score(self, files_data: List[Dict], cross_analysis: Dict) -> float:
        """Calcula score global"""
        if not files_data:
            return 0
        
        avg_score = sum(f['file_score'] for f in files_data) / len(files_data)
        cross_penalty = len(cross_analysis.get('cross_risks', [])) * 15
        
        arch_bonus = 0
        if cross_analysis.get('system_architecture', {}).get('completeness_score', 0) > 80:
            arch_bonus = 10
        
        return max(0, min(100, avg_score + cross_penalty - arch_bonus))
    
    def _generate_risks_summary(self, files_data: List[Dict]) -> Dict:
        """Gera resumo dos riscos"""
        all_risks = {}
        
        for risk_id, risk_info in AGENTIC_AI_RISKS.items():
            risk_scores = []
            affected_files = []
            
            for file_data in files_data:
                file_risk = file_data['risk_patterns'].get(risk_id, {})
                if file_risk.get('score', 0) > 0:
                    risk_scores.append(file_risk['score'])
                    affected_files.append(file_data['filename'])
            
            if risk_scores:
                avg_score = sum(risk_scores) / len(risk_scores)
                all_risks[risk_id] = {
                    "nome": risk_info["nome"],
                    "categoria": risk_info["categoria"],
                    "score": round(avg_score, 1),
                    "level": self._get_risk_level(avg_score),
                    "affected_files": affected_files,
                    "recommendations": self._get_recommendations(risk_id)
                }
        
        return all_risks
    
    def _get_recommendations(self, risk_id: str) -> List[str]:
        """RecomendaÃ§Ãµes por risco"""
        recommendations = {
            "1": ["Definir objetivos claros", "Implementar validaÃ§Ã£o de metas"],
            "2": ["Adicionar aprovaÃ§Ã£o humana", "Implementar thresholds"],
            "3": ["Rate limiting em APIs", "Usar variÃ¡veis de ambiente"],
            "7": ["Remover eval/exec", "Implementar validaÃ§Ã£o de entrada"]
        }
        return recommendations.get(risk_id, ["Implementar melhores prÃ¡ticas"])

class PDFReportGenerator:
    """Gerador de relatÃ³rios PDF usando ReportLab"""
    
    def generate_report(self, analysis_result: Dict) -> bytes:
        """Gera relatÃ³rio PDF completo"""
        buffer = io.BytesIO()
        
        # Criar documento
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        styles = getSampleStyleSheet()
        story = []
        
        # TÃ­tulo
        title = Paragraph("AgentRisk - RelatÃ³rio de AnÃ¡lise de CÃ³digo", styles['Title'])
        story.append(title)
        story.append(Spacer(1, 20))
        
        # InformaÃ§Ãµes gerais
        info_data = [
            ['Arquivos Analisados:', str(analysis_result['files_analyzed'])],
            ['Total de Linhas:', f"{analysis_result['total_lines']:,}"],
            ['Score Global:', f"{analysis_result['global_score']}/100"],
            ['NÃ­vel de Risco:', analysis_result['global_level']],
            ['Data da AnÃ¡lise:', datetime.datetime.now().strftime('%d/%m/%Y %H:%M')]
        ]
        
        info_table = Table(info_data, colWidths=[150, 200])
        info_table.setStyle(TableStyle([
            ('BACKGROUND', (0, 0), (-1, -1), HexColor('#f8f9fa')),
            ('TEXTCOLOR', (0, 0), (-1, -1), HexColor('#000000')),
            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),
            ('FONTNAME', (0, 0), (-1, -1), 'Helvetica'),
            ('FONTSIZE', (0, 0), (-1, -1), 10),
            ('BOTTOMPADDING', (0, 0), (-1, -1), 12),
        ]))
        
        story.append(info_table)
        story.append(Spacer(1, 30))
        
        # Score global destacado
        score_color = '#dc2626' if analysis_result['global_score'] >= 70 else '#f59e0b' if analysis_result['global_score'] >= 40 else '#10b981'
        score_text = f"<font color='{score_color}' size='16'><b>SCORE GLOBAL: {analysis_result['global_score']}/100</b></font>"
        score_para = Paragraph(score_text, styles['Normal'])
        story.append(score_para)
        story.append(Spacer(1, 20))
        
        # AnÃ¡lise por arquivo
        story.append(Paragraph("ANÃLISE DETALHADA POR ARQUIVO", styles['Heading2']))
        story.append(Spacer(1, 10))
        
        for i, file_data in enumerate(analysis_result['files_data'], 1):
            file_text = f"<b>{i}. {file_data['filename']}</b><br/>"
            file_text += f"Score: {file_data['file_score']}/100 | "
            file_text += f"Tipo: {file_data['file_type']} | "
            file_text += f"Linhas: {file_data['lines_count']:,}<br/>"
            file_text += f"ClassificaÃ§Ã£o: {file_data['classification']} | "
            file_text += f"NÃ­vel: {file_data['risk_level']}"
            
            if file_data['security_issues']:
                file_text += f"<br/><font color='red'>Problemas de SeguranÃ§a: {len(file_data['security_issues'])}</font>"
            
            file_para = Paragraph(file_text, styles['Normal'])
            story.append(file_para)
            story.append(Spacer(1, 10))
        
        # Top riscos
        if 'risks_summary' in analysis_result and analysis_result['risks_summary']:
            story.append(Spacer(1, 20))
            story.append(Paragraph("TOP 5 RISCOS DETECTADOS", styles['Heading2']))
            story.append(Spacer(1, 10))
            
            sorted_risks = sorted(
                analysis_result['risks_summary'].items(),
                key=lambda x: x[1]['score'],
                reverse=True
            )[:5]
            
            for i, (risk_id, risk_data) in enumerate(sorted_risks, 1):
                color = '#dc2626' if risk_data['level'] == 'Alto' else '#f59e0b' if risk_data['level'] == 'Moderado' else '#10b981'
                risk_text = f"<font color='{color}'><b>{i}. {risk_data['nome']}</b></font><br/>"
                risk_text += f"Score: {risk_data['score']}/100 | NÃ­vel: {risk_data['level']}<br/>"
                risk_text += f"Categoria: {risk_data['categoria']}<br/>"
                risk_text += f"Arquivos Afetados: {len(risk_data['affected_files'])}"
                
                if risk_data['recommendations']:
                    risk_text += f"<br/>RecomendaÃ§Ã£o: {risk_data['recommendations'][0]}"
                
                risk_para = Paragraph(risk_text, styles['Normal'])
                story.append(risk_para)
                story.append(Spacer(1, 15))
        
        # RodapÃ©
        story.append(Spacer(1, 30))
        footer_text = "RelatÃ³rio gerado automaticamente pelo AgentRisk<br/>"
        footer_text += "Baseado no documento 'Agentic AI in Financial Services - IBM Consulting (Maio/2025)'"
        footer_para = Paragraph(footer_text, styles['Normal'])
        story.append(footer_para)
        
        # Gerar PDF
        doc.build(story)
        buffer.seek(0)
        return buffer.getvalue()

# InicializaÃ§Ã£o
@st.cache_resource
def get_analyzer():
    return CodeAnalyzer(get_openai_client())

@st.cache_resource
def get_pdf_generator():
    return PDFReportGenerator()

def main():
    """FunÃ§Ã£o principal"""
    
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ›¡ï¸ AgentRisk</h1>
        <p>AnÃ¡lise de CÃ³digo para AvaliaÃ§Ã£o de Riscos em IA AutÃ´noma</p>
        <small>Streamlit Cloud | AnÃ¡lise Multi-Arquivo</small>
    </div>
    """, unsafe_allow_html=True)
    
    # Status
    col1, col2, col3 = st.columns(3)
    with col1:
        client = get_openai_client()
        if client:
            st.success("âœ… OpenAI: Ativo")
        else:
            st.info("â„¹ï¸ OpenAI: AnÃ¡lise Local")
    
    with col2:
        if PDF_AVAILABLE:
            st.success("âœ… PDF: ReportLab Ativo")
        else:
            st.error("âŒ PDF: ReportLab NecessÃ¡rio")
    
    with col3:
        st.success("âœ… AnÃ¡lise: 15 Riscos")
    
    # Sidebar
    with st.sidebar:
        st.header("ğŸ“‹ Menu")
        page = st.selectbox("Escolha:", ["ğŸ” AnÃ¡lise", "ğŸ“Š Dashboard", "âš™ï¸ Config"])
        
        if 'analysis_result' in st.session_state:
            result = st.session_state.analysis_result
            st.markdown("---")
            st.markdown("**ğŸ“Š Ãšltima AnÃ¡lise**")
            st.info(f"""
            ğŸ“ Arquivos: {result.get('files_analyzed', 0)}
            ğŸ“ Linhas: {result.get('total_lines', 0):,}
            ğŸ¯ Score: {result.get('global_score', 0)}/100
            """)
    
    # PÃ¡ginas
    if page == "ğŸ” AnÃ¡lise":
        show_analysis_page()
    elif page == "ğŸ“Š Dashboard":
        show_dashboard_page()
    else:
        show_config_page()

def show_analysis_page():
    """PÃ¡gina de anÃ¡lise de cÃ³digo"""
    
    st.header("ğŸ” AnÃ¡lise de CÃ³digo Multi-Arquivo")
    
    # Se jÃ¡ tem anÃ¡lise, mostrar resultados
    if 'analysis_result' in st.session_state:
        col1, col2 = st.columns([1, 4])
        with col1:
            if st.button("ğŸ”„ Nova AnÃ¡lise", type="secondary"):
                del st.session_state.analysis_result
                st.rerun()
        with col2:
            st.write("**AnÃ¡lise concluÃ­da - veja os resultados abaixo**")
        
        show_analysis_results(st.session_state.analysis_result)
        return
    
    # Interface de upload
    st.markdown("### ğŸ“¤ Upload dos Arquivos do Sistema")
    st.write("FaÃ§a upload dos arquivos de cÃ³digo do seu sistema para anÃ¡lise de riscos.")
    
    uploaded_files = st.file_uploader(
        "Selecione os arquivos",
        accept_multiple_files=True,
        type=SUPPORTED_EXTENSIONS,
        help="Arquivos de cÃ³digo, configuraÃ§Ã£o e documentaÃ§Ã£o suportados"
    )
    
    if uploaded_files:
        st.success(f"âœ… {len(uploaded_files)} arquivo(s) carregado(s)")
        
        # Preview dos arquivos
        with st.expander("ğŸ“‹ Arquivos Carregados", expanded=True):
            for file in uploaded_files:
                file_ext = os.path.splitext(file.name.lower())[1][1:]
                file_type = CodeAnalyzer(None)._get_file_type(file_ext)
                st.write(f"ğŸ“„ **{file.name}** - {file_type} ({file.size:,} bytes)")
        
        # BotÃ£o de anÃ¡lise
        if st.button("ğŸ” Analisar Sistema Completo", type="primary", use_container_width=True):
            with st.spinner("ğŸ”„ Analisando arquivos do sistema..."):
                # Progress bar
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                for i in range(101):
                    progress_bar.progress(i)
                    if i < 30:
                        status_text.text("ğŸ“– Lendo arquivos...")
                    elif i < 60:
                        status_text.text("ğŸ” Detectando padrÃµes de risco...")
                    elif i < 90:
                        status_text.text("ğŸ”— AnÃ¡lise cruzada...")
                    else:
                        status_text.text("ğŸ“Š Finalizando...")
                
                # AnÃ¡lise real
                analyzer = get_analyzer()
                analysis_result = analyzer.analyze_files(uploaded_files)
                
                if 'error' in analysis_result:
                    st.error(f"âŒ {analysis_result['error']}")
                    return
                
                # Salvar resultado
                st.session_state.analysis_result = analysis_result
                
                status_text.text("âœ… AnÃ¡lise concluÃ­da!")
                st.success("ğŸ‰ AnÃ¡lise de cÃ³digo concluÃ­da com sucesso!")
                st.balloons()
                st.rerun()
    
    else:
        # InstruÃ§Ãµes
        st.info("""
        ### ğŸ’¡ Como Usar
        
        1. **ğŸ“ Selecione os arquivos** principais do seu sistema
        2. **ğŸ” Clique em "Analisar"** para processar todos os arquivos  
        3. **ğŸ“Š Visualize os resultados** detalhados por arquivo
        4. **ğŸ“„ Gere relatÃ³rio PDF** profissional
        
        ### ğŸ“‹ Tipos Suportados
        - **CÃ³digo:** Python, JavaScript, Java, C#, PHP, Ruby, Go, C/C++
        - **Config:** JSON, YAML, XML
        - **Outros:** SQL, Markdown, Text
        
        ### ğŸ¯ AnÃ¡lise Inclui
        - âœ… **15 categorias de risco** especÃ­ficas para IA AutÃ´noma
        - âœ… **DetecÃ§Ã£o de vulnerabilidades** de seguranÃ§a
        - âœ… **AnÃ¡lise cruzada** entre arquivos  
        - âœ… **Score global** do sistema
        """)

def show_analysis_results(analysis_result: Dict):
    """Mostra resultados da anÃ¡lise"""
    
    st.header("ğŸ“Š Resultados da AnÃ¡lise")
    
    # MÃ©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ“ Arquivos", analysis_result['files_analyzed'])
    with col2:
        st.metric("ğŸ“ Total Linhas", f"{analysis_result['total_lines']:,}")
    with col3:
        st.metric("ğŸ¯ Score Global", f"{analysis_result['global_score']}/100")
    with col4:
        st.metric("â° MÃ©todo", "Multi-Arquivo")
    
    # Score visual
    global_score = analysis_result['global_score']
    global_level = analysis_result['global_level']
    
    score_class = "score-low" if global_score < 40 else "score-medium" if global_score < 70 else "score-high"
    emoji = "ğŸŸ¢" if global_score < 40 else "ğŸŸ¡" if global_score < 70 else "ğŸ”´"
    
    st.markdown(f"""
    <div class="score-container {score_class}">
        <h2>{emoji} Score Global do Sistema</h2>
        <h1>{global_score}/100</h1>
        <h3>NÃ­vel de Risco: {global_level}</h3>
    </div>
    """, unsafe_allow_html=True)
    
    # DistribuiÃ§Ã£o de riscos
    col1, col2, col3 = st.columns(3)
    
    high_count = sum(1 for f in analysis_result['files_data'] if f['risk_level'] == 'Alto')
    medium_count = sum(1 for f in analysis_result['files_data'] if f['risk_level'] == 'Moderado')
    low_count = sum(1 for f in analysis_result['files_data'] if f['risk_level'] == 'Baixo')
    
    with col1:
        st.metric("ğŸ”´ Riscos Altos", high_count)
    with col2:
        st.metric("ğŸŸ¡ Riscos Moderados", medium_count)
    with col3:
        st.metric("ğŸŸ¢ Riscos Baixos", low_count)
    
    # AnÃ¡lise por arquivo
    st.subheader("ğŸ“ AnÃ¡lise Detalhada por Arquivo")
    
    for file_data in analysis_result['files_data']:
        risk_class = f"risk-{file_data['risk_level'].lower()}"
        level_emoji = "ğŸŸ¢" if file_data['risk_level'] == "Baixo" else "ğŸŸ¡" if file_data['risk_level'] == "Moderado" else "ğŸ”´"
        
        st.markdown(f"""
        <div class="risk-card {risk_class}">
            <h4>{level_emoji} ğŸ“„ {file_data['filename']}</h4>
            <p><strong>Score:</strong> {file_data['file_score']}/100 | 
               <strong>Tipo:</strong> {file_data['file_type']} | 
               <strong>Linhas:</strong> {file_data['lines_count']:,}</p>
            <p><strong>ClassificaÃ§Ã£o:</strong> {file_data['classification']}</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Detalhes expandÃ­veis
        with st.expander(f"ğŸ” Detalhes - {file_data['filename']}"):
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š Resumo", "âš ï¸ Problemas", "ğŸ” Preview"])
            
            with tab1:
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Score", f"{file_data['file_score']}/100")
                    st.write(f"**Tipo:** {file_data['file_type']}")
                with col2:
                    st.metric("Linhas", f"{file_data['lines_count']:,}")
                    st.write(f"**ClassificaÃ§Ã£o:** {file_data['classification']}")
            
            with tab2:
                if file_data['security_issues']:
                    st.write("**ğŸš¨ Problemas de SeguranÃ§a:**")
                    for issue in file_data['security_issues']:
                        severity_color = "ğŸ”´" if issue['severity'] == 'HIGH' else "ğŸŸ¡"
                        st.write(f"{severity_color} **Linha {issue['line']}:** {issue['description']}")
                        with st.expander(f"Ver cÃ³digo - Linha {issue['line']}"):
                            st.code(issue['content'])
                else:
                    st.success("âœ… Nenhum problema crÃ­tico detectado")
                
                if file_data['critical_lines']:
                    st.write("**âš ï¸ Linhas CrÃ­ticas:**")
                    for critical in file_data['critical_lines']:
                        st.write(f"**Linha {critical['line_number']}:** {critical['reason']}")
            
            with tab3:
                if file_data['content_preview']:
                    st.write("**ğŸ“„ Preview do CÃ³digo:**")
                    st.code(file_data['content_preview'])
    
    # AnÃ¡lise cruzada
    if 'cross_analysis' in analysis_result and analysis_result['cross_analysis']['risks_found'] > 0:
        st.subheader("ğŸ”— AnÃ¡lise Cruzada Entre Arquivos")
        
        for cross_risk in analysis_result['cross_analysis']['cross_risks']:
            severity_color = "ğŸ”´" if cross_risk['severity'] == 'HIGH' else "ğŸŸ¡"
            st.warning(f"{severity_color} **{cross_risk['description']}**")
            st.write(f"**Arquivos afetados:** {', '.join(cross_risk['affected_files'])}")
    
    # Top riscos
    if 'risks_summary' in analysis_result and analysis_result['risks_summary']:
        st.subheader("ğŸ“‹ Top Riscos de IA AutÃ´noma Detectados")
        
        sorted_risks = sorted(
            analysis_result['risks_summary'].items(),
            key=lambda x: x[1]['score'],
            reverse=True
        )[:5]
        
        for risk_id, risk_data in sorted_risks:
            level_emoji = "ğŸ”´" if risk_data['level'] == "Alto" else "ğŸŸ¡" if risk_data['level'] == "Moderado" else "ğŸŸ¢"
            
            with st.expander(f"{level_emoji} {risk_id}. {risk_data['nome']} - {risk_data['score']}/100"):
                st.write(f"**Categoria:** {risk_data['categoria']}")
                st.write(f"**NÃ­vel:** {risk_data['level']}")
                st.write(f"**Arquivos afetados:** {len(risk_data['affected_files'])}")
                
                if risk_data['affected_files']:
                    st.write("**ğŸ“ Arquivos com este risco:**")
                    for filename in risk_data['affected_files']:
                        st.write(f"â€¢ {filename}")
                
                st.write("**ğŸ’¡ RecomendaÃ§Ãµes:**")
                for i, rec in enumerate(risk_data['recommendations'], 1):
                    st.write(f"{i}. {rec}")
    
    # BotÃµes de aÃ§Ã£o
    st.markdown("---")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“„ Gerar RelatÃ³rio PDF", use_container_width=True):
            with st.spinner("Gerando relatÃ³rio PDF..."):
                pdf_generator = get_pdf_generator()
                pdf_bytes = pdf_generator.generate_report(analysis_result)
                
                file_name = f"AgentRisk_Report_{analysis_result['files_analyzed']}files_{datetime.datetime.now().strftime('%Y%m%d_%H%M')}.pdf"
                
                st.download_button(
                    label="â¬‡ï¸ Download PDF",
                    data=pdf_bytes,
                    file_name=file_name,
                    mime="application/pdf",
                    use_container_width=True
                )
    
    with col2:
        if st.button("ğŸ“Š Ver Dashboard", use_container_width=True):
            st.session_state.show_dashboard = True
            st.rerun()
    
    with col3:
        if st.button("ğŸ”„ Nova AnÃ¡lise", use_container_width=True):
            del st.session_state.analysis_result
            st.rerun()

def show_dashboard_page():
    """Dashboard com grÃ¡ficos"""
    
    st.header("ğŸ“Š Dashboard de AnÃ¡lise")
    
    if 'analysis_result' not in st.session_state:
        st.warning("âš ï¸ Nenhuma anÃ¡lise disponÃ­vel. FaÃ§a uma anÃ¡lise primeiro.")
        if st.button("ğŸ”™ Voltar para AnÃ¡lise"):
            st.rerun()
        return
    
    analysis = st.session_state.analysis_result
    
    # MÃ©tricas principais
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Score Global", f"{analysis['global_score']}/100")
    with col2:
        high_files = len([f for f in analysis['files_data'] if f['risk_level'] == 'Alto'])
        st.metric("Arquivos Alto Risco", high_files)
    with col3:
        total_issues = sum(len(f['security_issues']) for f in analysis['files_data'])
        st.metric("Problemas SeguranÃ§a", total_issues)
    with col4:
        st.metric("Total Linhas", f"{analysis['total_lines']:,}")
    
    # GrÃ¡ficos
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š DistribuiÃ§Ã£o de Riscos")
        risk_levels = [f['risk_level'] for f in analysis['files_data']]
        risk_counts = {
            'Alto': risk_levels.count('Alto'),
            'Moderado': risk_levels.count('Moderado'),
            'Baixo': risk_levels.count('Baixo')
        }
        st.bar_chart(risk_counts)
    
    with col2:
        st.subheader("ğŸ”§ Tipos de Arquivo")
        file_types = [f['file_type'] for f in analysis['files_data']]
        type_counts = {}
        for ftype in set(file_types):
            type_counts[ftype] = file_types.count(ftype)
        st.bar_chart(type_counts)
    
    # Top arquivos crÃ­ticos
    st.subheader("ğŸš¨ Top 5 Arquivos Mais CrÃ­ticos")
    
    sorted_files = sorted(analysis['files_data'], key=lambda x: x['file_score'], reverse=True)[:5]
    
    for i, file_data in enumerate(sorted_files, 1):
        level_emoji = "ğŸ”´" if file_data['risk_level'] == "Alto" else "ğŸŸ¡" if file_data['risk_level'] == "Moderado" else "ğŸŸ¢"
        st.write(f"**#{i}** {level_emoji} **{file_data['filename']}** - {file_data['file_score']}/100 ({file_data['file_type']})")
    
    # Arquitetura do sistema
    if 'cross_analysis' in analysis and 'system_architecture' in analysis['cross_analysis']:
        st.subheader("ğŸ—ï¸ Arquitetura do Sistema")
        
        arch = analysis['cross_analysis']['system_architecture']
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Pontos de Entrada", arch['entry_points'])
            st.metric("APIs", arch['api_layers'])
        
        with col2:
            st.metric("Modelos de Dados", arch['data_models'])
            st.metric("SeguranÃ§a", arch['security_files'])
        
        with col3:
            st.metric("ConfiguraÃ§Ãµes", arch['config_files'])
            st.metric("Testes", arch['test_files'])
        
        completeness = arch.get('completeness_score', 0)
        st.progress(completeness / 100)
        st.write(f"**Completude da Arquitetura:** {completeness}/100")

def show_config_page():
    """PÃ¡gina de configuraÃ§Ãµes"""
    
    st.header("âš™ï¸ ConfiguraÃ§Ãµes do AgentRisk")
    
    # Status do sistema
    st.subheader("ğŸ“Š Status do Sistema")
    
    col1, col2 = st.columns(2)
    
    with col1:
        client = get_openai_client()
        if client:
            st.success("âœ… OpenAI: Configurada")
            if st.button("ğŸ§ª Testar OpenAI"):
                try:
                    with st.spinner("Testando..."):
                        response = client.chat.completions.create(
                            model="gpt-4o-mini",
                            messages=[{"role": "user", "content": "Teste"}],
                            max_tokens=5
                        )
                        st.success("âœ… Teste bem-sucedido!")
                except Exception as e:
                    st.error(f"âŒ Erro: {str(e)}")
        else:
            st.warning("âš ï¸ OpenAI: NÃ£o configurada")
            st.info("Configure OPENAI_API_KEY nos Secrets do Streamlit")
    
    with col2:
        st.info(f"""
        **Funcionalidades Ativas:**
        
        âœ… AnÃ¡lise multi-arquivo
        {'âœ…' if PDF_AVAILABLE else 'âŒ'} GeraÃ§Ã£o PDF (ReportLab)
        {'âœ…' if client else 'âš ï¸'} AnÃ¡lise com IA
        âœ… DetecÃ§Ã£o 15 riscos IA
        âœ… AnÃ¡lise cruzada arquivos
        âœ… Vulnerabilidades seguranÃ§a
        """)
    
    # InformaÃ§Ãµes do sistema
    st.subheader("ğŸ“‹ InformaÃ§Ãµes")
    
    st.info(f"""
    **AgentRisk v1.0**
    
    **Tipos de Arquivo:** {len(SUPPORTED_EXTENSIONS)} suportados
    **Riscos Analisados:** 15 categorias especÃ­ficas de IA AutÃ´noma
    **Baseado em:** IBM Consulting - Agentic AI in Financial Services (Maio/2025)
    **Deploy:** Streamlit Cloud
    **Ãšltima AtualizaÃ§Ã£o:** {datetime.datetime.now().strftime('%d/%m/%Y')}
    """)
    
    # Limpeza
    st.subheader("ğŸ—‘ï¸ Gerenciamento")
    
    if st.button("ğŸ—‘ï¸ Limpar AnÃ¡lise Atual"):
        if 'analysis_result' in st.session_state:
            del st.session_state.analysis_result
            st.success("âœ… AnÃ¡lise limpa!")
            st.rerun()
        else:
            st.info("â„¹ï¸ Nenhuma anÃ¡lise para limpar")

if __name__ == "__main__":
    main()
